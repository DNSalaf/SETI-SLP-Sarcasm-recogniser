{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP0S8nZbVpd_"
      },
      "source": [
        "# Speech and Language Processing (SLP)\n",
        "## Master Systèmes Embarqués et Traitement de l'Information (SETI)\n",
        "\n",
        "\n",
        "---------------------------\n",
        "\n",
        "### Project: **Sarcasm Detection in Natural Language Processing Applied to English Text**\n",
        "### Alaf DO NASCIMENTO SANTOS\n",
        "### Ianis GIRAUD\n",
        "---------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMAb82nfVJY5"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikAU-R3_XiAe"
      },
      "source": [
        "As a final project for the Speech and Language Processing course, and first actual AI project for the team, we decided to apply the acquired knowledge to a simple Natural Language Processing (NLP) task, principally in the area of text mining. We aim to train a model capable of recognising sarcasm in English texts. Our AI project, titled \"Sarcasm Detection in Natural Language Processing Applied to English Text\" addresses the challenge of deciphering sarcasm within individual sentences. The goal is to develop a system capable of providing a binary output—indicating whether a given sentence is sarcastic (true) or not (false).\n",
        "\n",
        "Sarcasm is a challenging being a popular research topic when it comes to text mining and semantics analysis. It is a form of verbal irony, which adds an extra layer of complexity to the already challenging field of text mining. In this context, the challenge extends to navigating the nuanced aspects of English expressions. Our approach integrates fundamental linguistic analysis with machine learning techniques. The model will be trained on datasets that capture instances of sarcasm within English sentences, considering the specific linguistic nuances and cultural context from the social media Reddit through the Self-Annotated Reddit Corpus (SARC) [1]. \n",
        "\n",
        "The potential applications of our system are numerous, ranging from improving sentiment analysis in customer feedback to enhancing the understanding of social media interactions. By highlighting the sentence-level analysis, our project strikes a balance between efficiency and effectiveness, offering a pragmatic solution for scenarios where processing entire texts in social media may be challenging.\n",
        "\n",
        "Since detecting sarcasm in natural language is a challenging task for NLP systems because it involves understanding not just the literal meaning of words but also the speaker's or writer's desired tone and context. Several approaches are utilised in NLP to address sarcasm detection, e.g., context analysis, sentiment analysis, pragmatic analysis, lexical and syntactic analysis. Despite advancements in NLP, sarcasm detection remains a complex and evolving area of research, as it requires models to understand the subtleties of human communication, context, and emotions. Models trained on large and diverse datasets with labelled examples of sarcasm are essential for improving their accuracy in detecting this nuanced form of expression. As a contribution to this field and proof of concept, we propose here a voting system, where 3 approaches were developed and each of them gives an \"opinion\" in either a sentence is sarcastic or not, and then the majority wins."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installing and Importing necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBrudgaZTSbm",
        "outputId": "6a41b6a5-0932-4dd3-92ab-cdeb420cf153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: matplotlib in /home/alaf/.local/lib/python3.10/site-packages (3.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/alaf/.local/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/alaf/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from matplotlib) (21.3)\n",
            "Requirement already satisfied: pillow>=8 in /usr/lib/python3/dist-packages (from matplotlib) (9.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/alaf/.local/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/alaf/.local/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/alaf/.local/lib/python3.10/site-packages (from matplotlib) (4.47.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /home/alaf/.local/lib/python3.10/site-packages (from matplotlib) (1.26.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: portalocker==2.8.2 in /home/alaf/.local/lib/python3.10/site-packages (2.8.2)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in /home/alaf/.local/lib/python3.10/site-packages (2.1.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/alaf/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/alaf/.local/lib/python3.10/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /home/alaf/.local/lib/python3.10/site-packages (from pandas) (1.26.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install matplotlib\n",
        "!pip3 install portalocker==2.8.2\n",
        "!pip3 install pandas\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "# from tqdm.notebook import tqdm\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpJSzobeWXxD"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The SARC dataset can be found at <https://nlp.cs.princeton.edu/old/SARC/2.0/>. It is a very large dataset, where each statement is self-annotated (sarcasm is labeled by the author) and provides the user, topic, and conversation context. In order to reduce the size of our dataset and only work with the target information, while keeping a limited complexity, we performed a preprocessing step.\n",
        "\n",
        "The comments are kept, along with some metadata, in a single very large json file. Because of memory constraints, it wasn't possible to load the whole file at once. To reduce it to a useable size and convert it to a format that could be easily loaded later, we used the following python code:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import bz2\n",
        "import re\n",
        "import ijson\n",
        "\n",
        "re_label = re.compile('\"([a-z0-9]+)\"')\n",
        "re_text = re.compile('\"text\": *\"(.*)\",')\n",
        "\n",
        "comments = \"../SARC/comments-pretty2.json.bz2\"\n",
        "\n",
        "ids = []\n",
        "texts = []\n",
        "\n",
        "level = 0\n",
        "\n",
        "with bz2.open(comments, \"rt\", encoding=\"utf-8\") as f:\n",
        "    f.readline()\n",
        "    line = f.readline()\n",
        "    while line:\n",
        "        line = line.strip()\n",
        "        if level==0 and not line.startswith(\"}\"):\n",
        "            ids.append(line.split('\"')[1])\n",
        "            level = 1\n",
        "        elif level==1:\n",
        "            m = re_text.match(line)\n",
        "            if m:\n",
        "                texts.append(bytes(m.group(1), \"utf-8\").decode(\"unicode_escape\"))\n",
        "            elif line.startswith(\"}\"):\n",
        "                level = 0\n",
        "        line = f.readline()\n",
        "\n",
        "print(len(ids), len(texts))\n",
        "\n",
        "df = pd.DataFrame({\"id\": ids, \"text\": texts})\n",
        "df.to_csv(\"comments.csv.bz2\")\n",
        "```\n",
        "This converts the json to a single csv file containing only an identifier and the text for each message. While the initial file would crash my computer when loaded with panda, this reduced version could fit in less than 4GB.\n",
        "\n",
        "The files containing the labels were provided in a csv-like format of the form `<parent1_id> [<parent2_id> ...] | <child1_id> [<child2_id ...] | <label1> [label2 ...]`. These two had to be converted to a more useable format using the following python code:\n",
        "```python\n",
        "import pandas as pd\n",
        "import bz2\n",
        "\n",
        "arr_parents = []\n",
        "arr_posts = []\n",
        "arr_labels = []\n",
        "\n",
        "labels = \"../SARC/test-balanced.csv.bz2\"\n",
        "with bz2.open(labels, \"rt\", encoding=\"utf-8\") as f:\n",
        "    line = f.readline()\n",
        "    while line:\n",
        "        parents, posts, labels = line.split(\"|\")\n",
        "        parent = parents.split()[-1]\n",
        "        posts = posts.split()\n",
        "        labels = labels.split()\n",
        "        for post, label in zip(posts, labels):\n",
        "            arr_parents.append(parent)\n",
        "            arr_posts.append(post)\n",
        "            arr_labels.append(int(label))\n",
        "        line = f.readline()\n",
        "\n",
        "df = pd.DataFrame({\"parent\": arr_parents, \"post\": arr_posts, \"label\": arr_labels})\n",
        "df.to_csv(\"test-balanced.csv.bz2\")\n",
        "```\n",
        "For each labelled message, this script keeps only its most recent parent and its label and organize everything in a simple csv table.\n",
        "\n",
        "Finally, most of the comments from `comments.csv.bz2` weren't referenced in the balanced dataset. To avoid having to load the whole 4GB of data in memory during training, we merged the comments' texts with their labels using this last script:\n",
        "```python\n",
        "import pandas as pd\n",
        "import bz2\n",
        "\n",
        "labels = \"test-balanced.csv.bz2\"\n",
        "texts = \"comments.csv.bz2\"\n",
        "\n",
        "with bz2.open(labels, \"rt\", encoding=\"utf-8\") as f:\n",
        "    df_labels = pd.read_csv(f, usecols=(\"parent\", \"post\", \"label\"))\n",
        "print(df_labels)\n",
        "    \n",
        "with bz2.open(texts, \"rt\", encoding=\"utf-8\") as f:\n",
        "    df_texts = pd.read_csv(f, usecols=(\"id\",\"text\"))\n",
        "print(df_texts)\n",
        "\n",
        "df_labels = pd.merge(df_labels, df_texts, how=\"left\", suffixes=(\"_label\", \"_text\"), left_on=\"parent\", right_on=\"id\").drop(columns=[\"parent\", \"id\"])\n",
        "print(df_labels)\n",
        "print(df_labels.info)\n",
        "df_labels = pd.merge(df_labels, df_texts, suffixes=(\"_parent\", \"_post\"), how=\"left\", left_on=\"post\", right_on=\"id\").drop(columns=[\"post\", \"id\"])\n",
        "print(df_labels)\n",
        "print(df_labels.info)\n",
        "\n",
        "df_labels.to_csv(\"merged-test.csv.bz2\")\n",
        "```\n",
        "\n",
        "\n",
        "Since we are not supposed to include external data directly in our submission, the clean corpus dataset has been uploaded to a personal GitHub repository. In the Python code, we access the files link hosted on Github and we load it through the **read_csv** function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "CqKwHIqaTSbq"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text_parent</th>\n",
              "      <th>text_post</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>I've been searching for the answer for this fo...</td>\n",
              "      <td>Religion must have the answer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>I've been searching for the answer for this fo...</td>\n",
              "      <td>It's obviously tracks from a giant water tract...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Michael Phelps Apologizes For \"Regrettable\" Be...</td>\n",
              "      <td>Wow...he smoked pot...oh lord hes such a horri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Michael Phelps Apologizes For \"Regrettable\" Be...</td>\n",
              "      <td>Wow, his girlfriend is uhm... Ah fuck it, he's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Utah wants to create a database to track the i...</td>\n",
              "      <td>I think the government should track every morm...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                        text_parent  \\\n",
              "0      1  I've been searching for the answer for this fo...   \n",
              "1      0  I've been searching for the answer for this fo...   \n",
              "2      1  Michael Phelps Apologizes For \"Regrettable\" Be...   \n",
              "3      0  Michael Phelps Apologizes For \"Regrettable\" Be...   \n",
              "4      0  Utah wants to create a database to track the i...   \n",
              "\n",
              "                                           text_post  \n",
              "0                      Religion must have the answer  \n",
              "1  It's obviously tracks from a giant water tract...  \n",
              "2  Wow...he smoked pot...oh lord hes such a horri...  \n",
              "3  Wow, his girlfriend is uhm... Ah fuck it, he's...  \n",
              "4  I think the government should track every morm...  "
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url_train = \"https://raw.githubusercontent.com/alafSantos/SETI-SLP-Sarcasm-recogniser/main/SARC/merged-train.csv\"\n",
        "# url_train = \"SARC/merged-train.csv\"\n",
        "df_train = pd.read_csv(url_train, usecols=[\"label\", \"text_parent\", \"text_post\"], encoding='utf-8')\n",
        "train_iter = df_train.iterrows()\n",
        "df_train.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text_parent</th>\n",
              "      <th>text_post</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The vast majority of Republicans rallied behin...</td>\n",
              "      <td>Yes, cuz tax cuts will help those w/o jobs!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>The vast majority of Republicans rallied behin...</td>\n",
              "      <td>If cutting taxes fails... cut taxes harder.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>\"...two-income families often have even less i...</td>\n",
              "      <td>Chalk it up to the ever-increasing cost of fre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>\"...two-income families often have even less i...</td>\n",
              "      <td>We're about to finally get affordable housing,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Heath Ledger Wins Oscar!</td>\n",
              "      <td>oh wow I am so surprised I never saw this coming</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                        text_parent  \\\n",
              "0      1  The vast majority of Republicans rallied behin...   \n",
              "1      0  The vast majority of Republicans rallied behin...   \n",
              "2      1  \"...two-income families often have even less i...   \n",
              "3      0  \"...two-income families often have even less i...   \n",
              "4      1                           Heath Ledger Wins Oscar!   \n",
              "\n",
              "                                           text_post  \n",
              "0        Yes, cuz tax cuts will help those w/o jobs!  \n",
              "1        If cutting taxes fails... cut taxes harder.  \n",
              "2  Chalk it up to the ever-increasing cost of fre...  \n",
              "3  We're about to finally get affordable housing,...  \n",
              "4   oh wow I am so surprised I never saw this coming  "
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url_test = \"https://raw.githubusercontent.com/alafSantos/SETI-SLP-Sarcasm-recogniser/main/SARC/merged-test.csv\"\n",
        "# url_test = \"SARC/merged-test.csv\"\n",
        "df_test = pd.read_csv(url_test, usecols=[\"label\", \"text_parent\", \"text_post\"], encoding='utf-8')\n",
        "test_iter = df_test.iterrows()\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "QZILR-zATSbr"
      },
      "outputs": [],
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for _, row in data_iter:\n",
        "        text = str(row[\"text_post\"])\n",
        "        yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: int(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Non-contextualised Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each word in the input text is assigned an\n",
        "embedding vectors. The vectors are then averaged together to get a fixed-size\n",
        "feature of the text. A linear transformation is applied to the feature to get a\n",
        "single output value.\n",
        "\n",
        "<img src=\"https://raw.github.com/alafSantos/SETI-SLP-Sarcasm-recogniser/main/IMG/non-contextualised.svg\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "V7uenQoATSbs"
      },
      "outputs": [],
      "source": [
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for _, row in batch:\n",
        "        _label = row[\"label\"]\n",
        "        _text = str(row[\"text_post\"])\n",
        "\n",
        "        label_list.append(label_pipeline(_label))\n",
        "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "        text_list.append(processed_text)\n",
        "        offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
        "\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "DxBYK4fBTSbt"
      },
      "outputs": [],
      "source": [
        "class TextClassificationModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "eB7AzWInTSbt"
      },
      "outputs": [],
      "source": [
        "num_class = 2 #1 or 0 always\n",
        "vocab_size = len(vocab)\n",
        "emsize = 64\n",
        "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNiSpuOIXmkQ"
      },
      "source": [
        "## Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The training dataset is split between training data and validation data with a 95 to 5 ratio. This allows to check the accuracy of our model between each epoch.\n",
        "\n",
        "The training is done by using a gradient descent over a cross entropy loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJXEMSstTSbu",
        "outputId": "1d281cf4-00c6-46db-d4c0-ea182e933f99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   0 |   500/ 3817 batches | accuracy    0.557\n",
            "| epoch   0 |  1000/ 3817 batches | accuracy    0.601\n",
            "| epoch   0 |  1500/ 3817 batches | accuracy    0.600\n",
            "| epoch   0 |  2000/ 3817 batches | accuracy    0.604\n",
            "| epoch   0 |  2500/ 3817 batches | accuracy    0.613\n",
            "| epoch   0 |  3000/ 3817 batches | accuracy    0.611\n",
            "| epoch   0 |  3500/ 3817 batches | accuracy    0.624\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   0 | time: 11.26s | valid accuracy    0.611 \n",
            "-----------------------------------------------------------\n",
            "| epoch   1 |   500/ 3817 batches | accuracy    0.633\n",
            "| epoch   1 |  1000/ 3817 batches | accuracy    0.633\n",
            "| epoch   1 |  1500/ 3817 batches | accuracy    0.636\n",
            "| epoch   1 |  2000/ 3817 batches | accuracy    0.635\n",
            "| epoch   1 |  2500/ 3817 batches | accuracy    0.631\n",
            "| epoch   1 |  3000/ 3817 batches | accuracy    0.635\n",
            "| epoch   1 |  3500/ 3817 batches | accuracy    0.636\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time: 11.25s | valid accuracy    0.611 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 3817 batches | accuracy    0.650\n",
            "| epoch   2 |  1000/ 3817 batches | accuracy    0.641\n",
            "| epoch   2 |  1500/ 3817 batches | accuracy    0.644\n",
            "| epoch   2 |  2000/ 3817 batches | accuracy    0.647\n",
            "| epoch   2 |  2500/ 3817 batches | accuracy    0.648\n",
            "| epoch   2 |  3000/ 3817 batches | accuracy    0.644\n",
            "| epoch   2 |  3500/ 3817 batches | accuracy    0.649\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time: 12.66s | valid accuracy    0.650 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 3817 batches | accuracy    0.658\n",
            "| epoch   3 |  1000/ 3817 batches | accuracy    0.651\n",
            "| epoch   3 |  1500/ 3817 batches | accuracy    0.656\n",
            "| epoch   3 |  2000/ 3817 batches | accuracy    0.654\n",
            "| epoch   3 |  2500/ 3817 batches | accuracy    0.654\n",
            "| epoch   3 |  3000/ 3817 batches | accuracy    0.654\n",
            "| epoch   3 |  3500/ 3817 batches | accuracy    0.657\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time: 11.76s | valid accuracy    0.626 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 3817 batches | accuracy    0.673\n",
            "| epoch   4 |  1000/ 3817 batches | accuracy    0.684\n",
            "| epoch   4 |  1500/ 3817 batches | accuracy    0.682\n",
            "| epoch   4 |  2000/ 3817 batches | accuracy    0.688\n",
            "| epoch   4 |  2500/ 3817 batches | accuracy    0.685\n",
            "| epoch   4 |  3000/ 3817 batches | accuracy    0.684\n",
            "| epoch   4 |  3500/ 3817 batches | accuracy    0.681\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time: 12.04s | valid accuracy    0.651 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 3817 batches | accuracy    0.685\n",
            "| epoch   5 |  1000/ 3817 batches | accuracy    0.685\n",
            "| epoch   5 |  1500/ 3817 batches | accuracy    0.686\n",
            "| epoch   5 |  2000/ 3817 batches | accuracy    0.686\n",
            "| epoch   5 |  2500/ 3817 batches | accuracy    0.683\n",
            "| epoch   5 |  3000/ 3817 batches | accuracy    0.689\n",
            "| epoch   5 |  3500/ 3817 batches | accuracy    0.681\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time: 11.34s | valid accuracy    0.654 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 3817 batches | accuracy    0.688\n",
            "| epoch   6 |  1000/ 3817 batches | accuracy    0.686\n",
            "| epoch   6 |  1500/ 3817 batches | accuracy    0.690\n",
            "| epoch   6 |  2000/ 3817 batches | accuracy    0.687\n",
            "| epoch   6 |  2500/ 3817 batches | accuracy    0.686\n",
            "| epoch   6 |  3000/ 3817 batches | accuracy    0.683\n",
            "| epoch   6 |  3500/ 3817 batches | accuracy    0.686\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time: 12.28s | valid accuracy    0.652 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 3817 batches | accuracy    0.689\n",
            "| epoch   7 |  1000/ 3817 batches | accuracy    0.689\n",
            "| epoch   7 |  1500/ 3817 batches | accuracy    0.692\n",
            "| epoch   7 |  2000/ 3817 batches | accuracy    0.690\n",
            "| epoch   7 |  2500/ 3817 batches | accuracy    0.691\n",
            "| epoch   7 |  3000/ 3817 batches | accuracy    0.690\n",
            "| epoch   7 |  3500/ 3817 batches | accuracy    0.690\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time: 12.25s | valid accuracy    0.653 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 3817 batches | accuracy    0.687\n",
            "| epoch   8 |  1000/ 3817 batches | accuracy    0.691\n",
            "| epoch   8 |  1500/ 3817 batches | accuracy    0.690\n",
            "| epoch   8 |  2000/ 3817 batches | accuracy    0.693\n",
            "| epoch   8 |  2500/ 3817 batches | accuracy    0.693\n",
            "| epoch   8 |  3000/ 3817 batches | accuracy    0.689\n",
            "| epoch   8 |  3500/ 3817 batches | accuracy    0.691\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time: 12.13s | valid accuracy    0.653 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 3817 batches | accuracy    0.691\n",
            "| epoch   9 |  1000/ 3817 batches | accuracy    0.691\n",
            "| epoch   9 |  1500/ 3817 batches | accuracy    0.689\n",
            "| epoch   9 |  2000/ 3817 batches | accuracy    0.689\n",
            "| epoch   9 |  2500/ 3817 batches | accuracy    0.690\n",
            "| epoch   9 |  3000/ 3817 batches | accuracy    0.693\n",
            "| epoch   9 |  3500/ 3817 batches | accuracy    0.689\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time: 11.00s | valid accuracy    0.653 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def train(dataloader, model=model):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predicted_label = model(text, offsets)\n",
        "        loss = criterion(predicted_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
        "                \"| accuracy {:8.3f}\".format(\n",
        "                    epoch, idx, len(dataloader), total_acc / total_count\n",
        "                )\n",
        "            )\n",
        "            total_acc, total_count = 0, 0\n",
        "\n",
        "def evaluate(dataloader, model=model):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for _, (label, text, offsets) in enumerate(dataloader):\n",
        "            predicted_label = model(text, offsets)\n",
        "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc / total_count\n",
        "\n",
        "\n",
        "            \n",
        "# Hyperparameters\n",
        "EPOCHS = 10  # epoch\n",
        "LR = 5  # learning rate\n",
        "BATCH_SIZE = 64  # batch size for training\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "\n",
        "train_iter = df_train.iterrows()\n",
        "test_iter = df_test.iterrows()\n",
        "\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "split_train_, split_valid_ = random_split(\n",
        "    train_dataset, [num_train, len(train_dataset) - num_train]\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "\n",
        "for epoch in range(0, EPOCHS):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "        scheduler.step()\n",
        "    else:\n",
        "        total_accu = accu_val\n",
        "    print(\"-\" * 59)\n",
        "    print(\n",
        "        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
        "        \"valid accuracy {:8.3f} \".format(\n",
        "            epoch, time.time() - epoch_start_time, accu_val\n",
        "        )\n",
        "    )\n",
        "    print(\"-\" * 59)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking the results of test dataset. The testing is done using a different dataset than the one used during training. This ensures that our model didn't accidentally overfit its training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXnAoQjHTSbu",
        "outputId": "96f4070a-7749-4cdd-d4e3-22a4c42e26fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking the results of test dataset.\n",
            "test accuracy    65.65%\n"
          ]
        }
      ],
      "source": [
        "print(\"Checking the results of test dataset.\")\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print(\"test accuracy {:8.2f}\".format(accu_test*100)+\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKpXSlDvTSbu",
        "outputId": "1dc67a55-80fd-4488-b7d6-4b02e64b5055"
      },
      "outputs": [],
      "source": [
        "def predict_no_context(text, text_pipeline=text_pipeline):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(text_pipeline(text))\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() == 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Contextualised Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each word in the input texts is assigned an embedding vectors. The vectors are then averaged together to get a fixed-size feature for each of the input texts. An hidden layer is used to \"mix\" the informations provided by each vector. Like before, a linear transformation is applied to the feature vector to get a single output value.\n",
        "\n",
        "<img src=\"https://raw.github.com/alafSantos/SETI-SLP-Sarcasm-recogniser/main/IMG/contextualised.svg\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_pipeline = lambda x, y: (vocab(tokenizer(str(x))), vocab(tokenizer(str(y))))\n",
        "label_pipeline = lambda x: int(x)\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_parent_list, text_post_list = [], [], []\n",
        "    offsets_parent, offsets_post = [0], [0]\n",
        "    for _, row in batch:\n",
        "        label = row['label']\n",
        "        text_post = row['text_post']\n",
        "        text_parent = row['text_parent']\n",
        "        label_list.append(label_pipeline(label))\n",
        "        tokens_parent, tokens_post = text_pipeline(text_parent, text_post)\n",
        "        processed_text_parent = torch.tensor(tokens_parent, dtype=torch.int64)\n",
        "        processed_text_post = torch.tensor(tokens_post, dtype=torch.int64)\n",
        "        text_parent_list.append(processed_text_parent)\n",
        "        text_post_list.append(processed_text_post)\n",
        "        offsets_parent.append(processed_text_parent.size(0))\n",
        "        offsets_post.append(processed_text_post.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.float)\n",
        "    offsets_parent = torch.tensor(offsets_parent[:-1]).cumsum(dim=0)\n",
        "    offsets_post = torch.tensor(offsets_post[:-1]).cumsum(dim=0)\n",
        "    text_parent_list = torch.cat(text_parent_list)\n",
        "    text_post_list = torch.cat(text_post_list)\n",
        "    return (label_list.to(device), text_parent_list.to(device), text_post_list.to(device), \n",
        "            offsets_parent.to(device), offsets_post.to(device))\n",
        "\n",
        "train_iter = df_train.iterrows()\n",
        "dataloader = DataLoader(\n",
        "    train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TextClassificationModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, embed_dim_post, hidden_dim):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding_parent = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
        "        self.embedding_post = nn.EmbeddingBag(vocab_size, embed_dim_post, sparse=False)\n",
        "        self.hidden = nn.Linear(embed_dim*2, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding_parent.weight.data.uniform_(-initrange, initrange)\n",
        "        self.embedding_post.weight.data.uniform_(-initrange, initrange)\n",
        "        self.hidden.weight.data.uniform_(-initrange, initrange)\n",
        "        self.hidden.bias.data.zero_()\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text_parent, text_post, offsets_parent, offsets_post):\n",
        "        embedded_parent = self.embedding_parent(text_parent, offsets_parent)\n",
        "        embedded_post = self.embedding_parent(text_post, offsets_post)\n",
        "        embedded = torch.hstack([embedded_parent,embedded_post])\n",
        "        middle = self.hidden(torch.sigmoid(embedded))\n",
        "        output = self.fc(torch.sigmoid(middle))\n",
        "        return torch.sigmoid(output).squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_iter = df_test.iterrows()\n",
        "emsize = 64\n",
        "embed_dim_post = 96\n",
        "hidden_size = 64\n",
        "model2 = TextClassificationModel(vocab_size, emsize, embed_dim_post, hidden_size).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training!\n",
            "| epoch   0 |   500/ 3817 batches | accuracy    0.500\n",
            "| epoch   0 |  1000/ 3817 batches | accuracy    0.504\n",
            "| epoch   0 |  1500/ 3817 batches | accuracy    0.503\n",
            "| epoch   0 |  2000/ 3817 batches | accuracy    0.500\n",
            "| epoch   0 |  2500/ 3817 batches | accuracy    0.499\n",
            "| epoch   0 |  3000/ 3817 batches | accuracy    0.499\n",
            "| epoch   0 |  3500/ 3817 batches | accuracy    0.501\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   0 | time: 18.33s | valid accuracy    0.503 \n",
            "-----------------------------------------------------------\n",
            "| epoch   1 |   500/ 3817 batches | accuracy    0.501\n",
            "| epoch   1 |  1000/ 3817 batches | accuracy    0.505\n",
            "| epoch   1 |  1500/ 3817 batches | accuracy    0.503\n",
            "| epoch   1 |  2000/ 3817 batches | accuracy    0.507\n",
            "| epoch   1 |  2500/ 3817 batches | accuracy    0.513\n",
            "| epoch   1 |  3000/ 3817 batches | accuracy    0.516\n",
            "| epoch   1 |  3500/ 3817 batches | accuracy    0.522\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time: 17.37s | valid accuracy    0.508 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 3817 batches | accuracy    0.532\n",
            "| epoch   2 |  1000/ 3817 batches | accuracy    0.535\n",
            "| epoch   2 |  1500/ 3817 batches | accuracy    0.543\n",
            "| epoch   2 |  2000/ 3817 batches | accuracy    0.545\n",
            "| epoch   2 |  2500/ 3817 batches | accuracy    0.553\n",
            "| epoch   2 |  3000/ 3817 batches | accuracy    0.552\n",
            "| epoch   2 |  3500/ 3817 batches | accuracy    0.564\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time: 17.46s | valid accuracy    0.537 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 3817 batches | accuracy    0.571\n",
            "| epoch   3 |  1000/ 3817 batches | accuracy    0.574\n",
            "| epoch   3 |  1500/ 3817 batches | accuracy    0.583\n",
            "| epoch   3 |  2000/ 3817 batches | accuracy    0.579\n",
            "| epoch   3 |  2500/ 3817 batches | accuracy    0.588\n",
            "| epoch   3 |  3000/ 3817 batches | accuracy    0.584\n",
            "| epoch   3 |  3500/ 3817 batches | accuracy    0.590\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time: 19.29s | valid accuracy    0.547 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 3817 batches | accuracy    0.598\n",
            "| epoch   4 |  1000/ 3817 batches | accuracy    0.599\n",
            "| epoch   4 |  1500/ 3817 batches | accuracy    0.603\n",
            "| epoch   4 |  2000/ 3817 batches | accuracy    0.603\n",
            "| epoch   4 |  2500/ 3817 batches | accuracy    0.606\n",
            "| epoch   4 |  3000/ 3817 batches | accuracy    0.605\n",
            "| epoch   4 |  3500/ 3817 batches | accuracy    0.609\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time: 18.85s | valid accuracy    0.522 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 3817 batches | accuracy    0.635\n",
            "| epoch   5 |  1000/ 3817 batches | accuracy    0.642\n",
            "| epoch   5 |  1500/ 3817 batches | accuracy    0.641\n",
            "| epoch   5 |  2000/ 3817 batches | accuracy    0.639\n",
            "| epoch   5 |  2500/ 3817 batches | accuracy    0.636\n",
            "| epoch   5 |  3000/ 3817 batches | accuracy    0.642\n",
            "| epoch   5 |  3500/ 3817 batches | accuracy    0.638\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time: 17.92s | valid accuracy    0.629 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 3817 batches | accuracy    0.639\n",
            "| epoch   6 |  1000/ 3817 batches | accuracy    0.640\n",
            "| epoch   6 |  1500/ 3817 batches | accuracy    0.639\n",
            "| epoch   6 |  2000/ 3817 batches | accuracy    0.643\n",
            "| epoch   6 |  2500/ 3817 batches | accuracy    0.643\n",
            "| epoch   6 |  3000/ 3817 batches | accuracy    0.642\n",
            "| epoch   6 |  3500/ 3817 batches | accuracy    0.644\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time: 18.45s | valid accuracy    0.637 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 3817 batches | accuracy    0.640\n",
            "| epoch   7 |  1000/ 3817 batches | accuracy    0.644\n",
            "| epoch   7 |  1500/ 3817 batches | accuracy    0.643\n",
            "| epoch   7 |  2000/ 3817 batches | accuracy    0.641\n",
            "| epoch   7 |  2500/ 3817 batches | accuracy    0.643\n",
            "| epoch   7 |  3000/ 3817 batches | accuracy    0.645\n",
            "| epoch   7 |  3500/ 3817 batches | accuracy    0.646\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time: 17.74s | valid accuracy    0.640 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 3817 batches | accuracy    0.645\n",
            "| epoch   8 |  1000/ 3817 batches | accuracy    0.652\n",
            "| epoch   8 |  1500/ 3817 batches | accuracy    0.641\n",
            "| epoch   8 |  2000/ 3817 batches | accuracy    0.643\n",
            "| epoch   8 |  2500/ 3817 batches | accuracy    0.639\n",
            "| epoch   8 |  3000/ 3817 batches | accuracy    0.648\n",
            "| epoch   8 |  3500/ 3817 batches | accuracy    0.647\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time: 17.53s | valid accuracy    0.641 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 3817 batches | accuracy    0.643\n",
            "| epoch   9 |  1000/ 3817 batches | accuracy    0.650\n",
            "| epoch   9 |  1500/ 3817 batches | accuracy    0.644\n",
            "| epoch   9 |  2000/ 3817 batches | accuracy    0.648\n",
            "| epoch   9 |  2500/ 3817 batches | accuracy    0.646\n",
            "| epoch   9 |  3000/ 3817 batches | accuracy    0.649\n",
            "| epoch   9 |  3500/ 3817 batches | accuracy    0.644\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time: 17.44s | valid accuracy    0.635 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def train(dataloader, model=model2):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "\n",
        "    for idx, (label, text_parent, text_post, offsets_parent, offsets_post) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predicted_label = model(text_parent, text_post, offsets_parent, offsets_post)\n",
        "        loss = criterion(predicted_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        predicted_label[predicted_label > 0.5] = 1\n",
        "        predicted_label[predicted_label <= 0.5] = 0\n",
        "        total_acc += (predicted_label == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
        "                \"| accuracy {:8.3f}\".format(\n",
        "                    epoch, idx, len(dataloader), total_acc / total_count\n",
        "                )\n",
        "            )\n",
        "            total_acc, total_count = 0, 0\n",
        "\n",
        "\n",
        "def evaluate(dataloader, model=model2):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _, (label, text_parent, text_post, offsets_parent, offsets_post) in enumerate(dataloader):\n",
        "            predicted_label = model(text_parent, text_post, offsets_parent, offsets_post)\n",
        "            predicted_label[predicted_label > 0.5] = 1\n",
        "            predicted_label[predicted_label <= 0.5] = 0\n",
        "            total_acc += (predicted_label == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc / total_count\n",
        "\n",
        "# Hyperparameters\n",
        "EPOCHS = 10  # epoch\n",
        "LR = 5  # learning rate\n",
        "BATCH_SIZE = 64  # batch size for training\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model2.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "train_iter = df_train.iterrows()\n",
        "test_iter = df_test.iterrows()\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "split_train_, split_valid_ = random_split(\n",
        "    train_dataset, [num_train, len(train_dataset) - num_train]\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "\n",
        "print(\"Starting training!\")\n",
        "for epoch in range(0, EPOCHS):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "        scheduler.step()\n",
        "    else:\n",
        "        total_accu = accu_val\n",
        "    print(\"-\" * 59)\n",
        "    print(\n",
        "        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
        "        \"valid accuracy {:8.3f} \".format(\n",
        "            epoch, time.time() - epoch_start_time, accu_val\n",
        "        )\n",
        "    )\n",
        "    print(\"-\" * 59)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking the results of test dataset.\n",
            "test accuracy    63.40%\n"
          ]
        }
      ],
      "source": [
        "print(\"Checking the results of test dataset.\")\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print(\"test accuracy {:8.2f}\".format(accu_test*100)+\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_context(text_parent, text_post, text_pipeline=text_pipeline):\n",
        "    with torch.no_grad():\n",
        "        text_parent, text_post = text_pipeline(text_parent, text_post)\n",
        "        output = model2( torch.tensor(text_parent), torch.tensor(text_post), \n",
        "                        torch.tensor([0]), torch.tensor([0]) )\n",
        "        return output.item() > 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## VADER Sentiment Analysis Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With VADER approach we can take all the words in a sentence and then set a value, either negative, positive or neutral and combines those values in order to tell us if the sentence itself is more globally positive or negative. VADER gives us values from -1 to 1 for each word and a global compound (which we will be using here). From [6] we have a study showing that most of the time sarcasm comes with positive sentences, but in a negative situation or context. For simplicity, we will be using VADER as a voter in our final decision by defining a sentence as sarcastic when it has a positive or neutral compound in the answer, otherwise it will be non sarcastic; together with a negative or neutral context. It is important to highlight that VADER doesn't take into account the relationship between the words, which is very important in the real world. But it will be used here as a voter for simplicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking the results of test dataset.\n",
            "test accuracy    50.38%\n"
          ]
        }
      ],
      "source": [
        "test_iter = df_test.iterrows()\n",
        "\n",
        "def evaluate():\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    for _, row in test_iter:\n",
        "        label = row['label']\n",
        "        text_post = str(row['text_post'])\n",
        "        text_parent = str(row['text_parent'])\n",
        "        predicted_label = predict_vader(text_parent, text_post)\n",
        "        total_acc += (predicted_label == (label==1))\n",
        "        total_count += 1\n",
        "    \n",
        "    return total_acc / total_count\n",
        "\n",
        "\n",
        "def predict_vader(context, answer):\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    vader1_result = sia.polarity_scores(context)[\"compound\"]\n",
        "    vader2_result = sia.polarity_scores(answer)[\"compound\"]\n",
        "    result = (vader1_result <= 0 and vader2_result >= 0)\n",
        "    return result\n",
        "\n",
        "\n",
        "print(\"Checking the results of test dataset.\")\n",
        "accu_test = evaluate()\n",
        "print(\"test accuracy {:8.2f}\".format(accu_test*100)+\"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demonstration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the end, to demonstrate our sarcasm recognition system, we have a voting system. Each approach developed will give a vote, 0 for non sarcastic, 1 for sarcastic, and if the sum of the votes is greater than 1 (2 or 3) it means that the input is sarcastic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Situation  0 : When something bad happens\n",
            "Remark:  That's just what I needed today!\n",
            "M1:  False\n",
            "M2:  True\n",
            "M3:  True\n",
            "Voting Result:  True\n",
            "--------------------\n",
            "Situation  1 : When you expected something to happen, especially after warning someone about it\n",
            "Remark:  Well, what a surprise.\n",
            "M1:  True\n",
            "M2:  True\n",
            "M3:  True\n",
            "Voting Result:  True\n",
            "--------------------\n",
            "Situation  2 : Chart showing how people's political views change as they age, based on 172,853 people's self-proclaimed political views on OKcupid.\n",
            "Remark:  Good lord... my chart is the exact opposite of this.\n",
            "M1:  False\n",
            "M2:  False\n",
            "M3:  True\n",
            "Voting Result:  False\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Some of the example sentences here are taken from https://www.yourdictionary.com/articles/examples-sarcasm-meaning-types\n",
        "'''\n",
        "\n",
        "input1 = [\n",
        "    \"When something bad happens\",\n",
        "    \"When you expected something to happen, especially after warning someone about it\",\n",
        "    \"Chart showing how people's political views change as they age, based on 172,853 people's self-proclaimed political views on OKcupid.\",\n",
        "          ]\n",
        "\n",
        "\n",
        "input2 = [\n",
        "    \"That's just what I needed today!\",\n",
        "    \"Well, what a surprise.\",\n",
        "    \"Good lord... my chart is the exact opposite of this.\",\n",
        "          ]\n",
        "\n",
        "model = model.to(\"cpu\")\n",
        "model2 = model2.to(\"cpu\")\n",
        "\n",
        "for i in range(0, len(input1)):\n",
        "    noContext_vote = predict_no_context(input2[i])\n",
        "    context_vote = predict_context(input1[i], input2[i])\n",
        "    vader_vote = predict_vader(input1[i], input2[i])\n",
        "    result = sum([noContext_vote, context_vote, vader_vote]) > 1\n",
        "\n",
        "    print(\"--------------------\\nSituation \", i, \":\", input1[i])\n",
        "    print(\"Remark: \", input2[i])\n",
        "    print(\"M1: \", noContext_vote)\n",
        "    print(\"M2: \", context_vote)\n",
        "    print(\"M3: \", vader_vote)\n",
        "    print(\"Voting Result: \", result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9Xlii7NXuOR"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The project started with a small survey to better understand the possibilities and choose a subject that could be interesting to the group members. After that, we began to study some basic Machine Learning concepts in order to get a better idea of what could be done, together with some text mining theory. Then, we read the PyTorch documentation aiming to find a starting point. Finally, we got into the coding phase, where [5] was extremely important to have some kind of comparison and basis for our code. Throughout our work, we developed 3 approaches for sarcasm recognition so we were able to apply the Condorcet's jury theorem in order to obtain a more trustful and robust system to give us binary predictions in either a sentence is sarcastic or not. We have worked with the SARC corpus, containing Reddit comments self annotated by the authors.\n",
        "\n",
        "1. For the first model, based on [1] and [5], we designed a simple sarcasm recognition system, taking only a sentence as input for the analysis (no context), based on a Pytorch example for sentiment analysis. There we had a test's accuracy over 65%.\n",
        "\n",
        "2. Concerning the second model, based on [1] and [5], using the same self-annotated dataset, we made some modifications in the first model in order to take into account the context in which the comment was written (parent text). This time we achieved a test's accuracy of 60%.\n",
        "\n",
        "3. Finally, as a way to have a third opinion in the voting process suggested by the Condorcet's jury theorem and explored in [7], we used the pretrained model VADER to do sentiment analysis with context. The idea here was to consider the contrast between the situation and the target sentence, in [6] it was studied the relationship between negative situations/contexts and positive answers/sentences as a way to express sarcasm in the social media Twitter. With this third and last approach, we reached a test's accuracy over 50%.\n",
        "\n",
        "Since the third approach did not give us good accuracy, it is possible to conclude that our voting system is not reliable taking into account the mentioned theorem, but the individual results from the two first approaches are a significant achievement for a first text mining project applied to NLP challenges. For the continuation of this project, exploring Condorcet's jury theorem and developing more reliable voters could be a promising direction. If we want to use this solution in embedded applications, decreasing the system complexity can be also a key. Finally, capturing semantic relationships within multiword expressions using Named Entity Recognition (NER), has the power to increase the system's accuracy since sarcasm may involve playing with the literal meaning of named entities or making ironic references to them. Concluding with another possible branch of this project, we could go forward and expand it to speech analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap0SJ_Ja4QQd"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUsZLcPc4SAd"
      },
      "source": [
        "[1] Khodak, M., Saunshi, N. and Vodrahalli, K., 2017. A large self-annotated corpus for sarcasm. arXiv preprint arXiv:1704.05579.\n",
        "\n",
        "[2] Attardo, S. and Raskin, V., 1991. Script theory revis (it) ed: Joke similarity and joke representation model.\n",
        "\n",
        "[3] Farha, I.A., Oprea, S., Wilson, S. and Magdy, W., 2022, July. Semeval-2022 task 6: isarcasmeval, intended sarcasm detection in english and arabic. In The 16th International Workshop on Semantic Evaluation 2022 (pp. 802-814). Association for Computational Linguistics.\n",
        "\n",
        "[4] Ashwitha, A., Shruthi, G., Shruthi, H.R., Upadhyaya, M., Ray, A.P. and Manjunath, T.C., 2021. Sarcasm detection in natural language processing. Materials Today: Proceedings, 37, pp.3324-3331.\n",
        "\n",
        "[5] Adam Paszke et al. “Automatic differentiation in PyTorch”. In: (2017).\n",
        "\n",
        "[6] Riloff, E., Qadir, A., Surve, P., De Silva, L., Gilbert, N. and Huang, R., 2013, October. Sarcasm as contrast between a positive sentiment and negative situation. In Proceedings of the 2013 conference on empirical methods in natural language processing (pp. 704-714).\n",
        "\n",
        "[7] Ariharan, V., Eswaran, S.P., Vempati, S. and Anjum, N., 2019. Machine learning quorum decider (MLQD) for large scale IoT deployments. Procedia Computer Science, 151, pp.959-964.\n",
        "\n",
        "[8] Sag, I.A., Baldwin, T., Bond, F., Copestake, A. and Flickinger, D., 2002. Multiword expressions: A pain in the neck for NLP. In Computational Linguistics and Intelligent Text Processing: Third International Conference, CICLing 2002 Mexico City, Mexico, February 17–23, 2002 Proceedings 3 (pp. 1-15). Springer Berlin Heidelberg.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
