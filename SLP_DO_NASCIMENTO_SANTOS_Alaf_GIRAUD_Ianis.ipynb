{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP0S8nZbVpd_"
      },
      "source": [
        "# Speech and Language Processing (SLP)\n",
        "## Master Systèmes Embarqués et Traitement de l'Information (SETI)\n",
        "\n",
        "\n",
        "---------------------------\n",
        "\n",
        "### Project: **Sarcasm Detection in Natural Language Processing Applied to English Text**\n",
        "### Alaf DO NASCIMENTO SANTOS\n",
        "### Ianis GIRAUD\n",
        "---------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMAb82nfVJY5"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikAU-R3_XiAe"
      },
      "source": [
        "As a final project for the Speech and Language Processing course, and first actual AI project for the team, we decided to apply the acquired knowledge to a simple Natural Language Processing (NLP) task, principally in the area of text mining. We aim to train a model capable of recognising sarcasm in English texts.\n",
        "\n",
        "In the complex landscape of NLP, our AI project, titled \"Sarcasm Detection in Natural Language Processing Applied to English Text\" addresses the challenge of deciphering sarcasm within individual sentences. Our goal is to develop a model capable of providing a binary output—indicating whether a given sentence is sarcastic (true) or not (false).\n",
        "\n",
        "Unlike more powerful systems, our focus is on simplicity and resource efficiency, especially important when dealing with text mining tasks. Sarcasm, a form of verbal irony, adds an extra layer of complexity to the already challenging field of text analysis. In this context, the challenge extends to navigating the nuanced aspects of English expressions.\n",
        "\n",
        "Our approach integrates fundamental linguistic analysis with machine learning techniques. The model will be trained on datasets that capture instances of sarcasm within English sentences, considering the specific linguistic nuances and cultural context from the social media Reddit through the Self-Annotated Reddit Corpus (SARC) [1]. This training process aims to equip our AI system with the ability to discern sarcasm efficiently, even when presented with the constraints of text mining tasks.\n",
        "\n",
        "The potential applications of our system are numerous, ranging from improving sentiment analysis in customer feedback to enhancing the understanding of social media interactions. By highlighting the sentence-level analysis, our project strikes a balance between efficiency and effectiveness, offering a pragmatic solution for scenarios where processing entire texts in social media may be challenging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installing and Importing necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBrudgaZTSbm",
        "outputId": "6a41b6a5-0932-4dd3-92ab-cdeb420cf153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: matplotlib in /home/alaf/.local/lib/python3.10/site-packages (3.8.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/lib/python3/dist-packages (from matplotlib) (9.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/alaf/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from matplotlib) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/alaf/.local/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/alaf/.local/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/alaf/.local/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /home/alaf/.local/lib/python3.10/site-packages (from matplotlib) (1.26.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/alaf/.local/lib/python3.10/site-packages (from matplotlib) (4.47.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: portalocker==2.8.2 in /home/alaf/.local/lib/python3.10/site-packages (2.8.2)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in /home/alaf/.local/lib/python3.10/site-packages (2.1.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /home/alaf/.local/lib/python3.10/site-packages (from pandas) (1.26.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/alaf/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/alaf/.local/lib/python3.10/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install matplotlib\n",
        "!pip3 install portalocker==2.8.2\n",
        "!pip3 install pandas\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from tqdm.notebook import tqdm\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpJSzobeWXxD"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The SARC dataset can be found at <https://nlp.cs.princeton.edu/old/SARC/2.0/>. It is a very large dataset, where each statement is self-annotated (sarcasm is labeled by the author) and provides the user, topic, and conversation context. In order to reduce the size of our dataset and only work with the target information, while keeping a limited complexity, we performed a preprocessing step in C code. The following C code was used to clean the json file containing the corpus raw data.\n",
        "\n",
        "\n",
        "```\n",
        "#include <stdio.h>\n",
        "\n",
        "\n",
        "int main(void) {\n",
        "    int c;\n",
        "    int n;\n",
        "    int level = 0;\n",
        "\n",
        "    while ((c = getchar()) != EOF) {\n",
        "        if (c=='[' || c=='{') {\n",
        "            putchar(c);\n",
        "            putchar('\\n');\n",
        "            level++;\n",
        "            for (int i=0; i<level; i++) {\n",
        "                putchar('\\t');\n",
        "            }\n",
        "        } else if (c==']' || c=='}') {\n",
        "            putchar('\\n');\n",
        "            level--;\n",
        "            for (int i=0; i<level; i++) {\n",
        "                putchar('\\t');\n",
        "            }\n",
        "            putchar(c);\n",
        "        } else if (c==',') {\n",
        "            putchar(c);\n",
        "            putchar('\\n');\n",
        "            for (int i=0; i<level; i++) {\n",
        "                putchar('\\t');\n",
        "            }\n",
        "        } else {\n",
        "            putchar(c);\n",
        "        }\n",
        "    }\n",
        "    return 0;\n",
        "}\n",
        "```\n",
        "\n",
        "EXPLAIN HERE HOW WE PASSED FROM ONE UNIQUE JSON TO TWO CSVs FILES (I DIDN'T GET)\n",
        "\n",
        "\n",
        "Since we are not supposed to include external data directly in our submission, the clean corpus dataset has been uploaded to a personal GitHub repository. In the Python code, we access the files link hosted on Github and we load it through the **read_csv** function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "CqKwHIqaTSbq"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text_parent</th>\n",
              "      <th>text_post</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>I've been searching for the answer for this fo...</td>\n",
              "      <td>Religion must have the answer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>I've been searching for the answer for this fo...</td>\n",
              "      <td>It's obviously tracks from a giant water tract...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Michael Phelps Apologizes For \"Regrettable\" Be...</td>\n",
              "      <td>Wow...he smoked pot...oh lord hes such a horri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Michael Phelps Apologizes For \"Regrettable\" Be...</td>\n",
              "      <td>Wow, his girlfriend is uhm... Ah fuck it, he's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Utah wants to create a database to track the i...</td>\n",
              "      <td>I think the government should track every morm...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                        text_parent  \\\n",
              "0      1  I've been searching for the answer for this fo...   \n",
              "1      0  I've been searching for the answer for this fo...   \n",
              "2      1  Michael Phelps Apologizes For \"Regrettable\" Be...   \n",
              "3      0  Michael Phelps Apologizes For \"Regrettable\" Be...   \n",
              "4      0  Utah wants to create a database to track the i...   \n",
              "\n",
              "                                           text_post  \n",
              "0                      Religion must have the answer  \n",
              "1  It's obviously tracks from a giant water tract...  \n",
              "2  Wow...he smoked pot...oh lord hes such a horri...  \n",
              "3  Wow, his girlfriend is uhm... Ah fuck it, he's...  \n",
              "4  I think the government should track every morm...  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url_train = \"https://raw.githubusercontent.com/alafSantos/SETI-SLP-Sarcasm-recogniser/main/SARC/merged-train.csv\"\n",
        "url_train = \"SARC/merged-train.csv\"\n",
        "df_train = pd.read_csv(url_train, usecols=[\"label\", \"text_parent\", \"text_post\"], encoding='utf-8')\n",
        "train_iter = df_train.iterrows()\n",
        "df_train.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text_parent</th>\n",
              "      <th>text_post</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The vast majority of Republicans rallied behin...</td>\n",
              "      <td>Yes, cuz tax cuts will help those w/o jobs!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>The vast majority of Republicans rallied behin...</td>\n",
              "      <td>If cutting taxes fails... cut taxes harder.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>\"...two-income families often have even less i...</td>\n",
              "      <td>Chalk it up to the ever-increasing cost of fre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>\"...two-income families often have even less i...</td>\n",
              "      <td>We're about to finally get affordable housing,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Heath Ledger Wins Oscar!</td>\n",
              "      <td>oh wow I am so surprised I never saw this coming</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                        text_parent  \\\n",
              "0      1  The vast majority of Republicans rallied behin...   \n",
              "1      0  The vast majority of Republicans rallied behin...   \n",
              "2      1  \"...two-income families often have even less i...   \n",
              "3      0  \"...two-income families often have even less i...   \n",
              "4      1                           Heath Ledger Wins Oscar!   \n",
              "\n",
              "                                           text_post  \n",
              "0        Yes, cuz tax cuts will help those w/o jobs!  \n",
              "1        If cutting taxes fails... cut taxes harder.  \n",
              "2  Chalk it up to the ever-increasing cost of fre...  \n",
              "3  We're about to finally get affordable housing,...  \n",
              "4   oh wow I am so surprised I never saw this coming  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url_test = \"https://raw.githubusercontent.com/alafSantos/SETI-SLP-Sarcasm-recogniser/main/SARC/merged-test.csv\"\n",
        "url_test = \"SARC/merged-test.csv\"\n",
        "df_test = pd.read_csv(url_test, usecols=[\"label\", \"text_parent\", \"text_post\"], encoding='utf-8')\n",
        "test_iter = df_test.iterrows()\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "EXPLIQUER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "QZILR-zATSbr"
      },
      "outputs": [],
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for _, row in data_iter:\n",
        "        text = str(row[\"text_post\"])\n",
        "        yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: int(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NO CONTEXT APPROACH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "V7uenQoATSbs"
      },
      "outputs": [],
      "source": [
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for index, row in batch:\n",
        "        _label = row[\"label\"]\n",
        "        _text = str(row[\"text_post\"])\n",
        "\n",
        "        label_list.append(label_pipeline(_label))\n",
        "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "        text_list.append(processed_text)\n",
        "        offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
        "\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "DxBYK4fBTSbt"
      },
      "outputs": [],
      "source": [
        "class TextClassificationModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "eB7AzWInTSbt"
      },
      "outputs": [],
      "source": [
        "num_class = 2 #1 or 0 always\n",
        "vocab_size = len(vocab)\n",
        "emsize = 64\n",
        "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNiSpuOIXmkQ"
      },
      "source": [
        "## Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJXEMSstTSbu",
        "outputId": "1d281cf4-00c6-46db-d4c0-ea182e933f99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   0 |   500/ 3817 batches | accuracy    0.565\n",
            "| epoch   0 |  1000/ 3817 batches | accuracy    0.595\n",
            "| epoch   0 |  1500/ 3817 batches | accuracy    0.608\n",
            "| epoch   0 |  2000/ 3817 batches | accuracy    0.607\n",
            "| epoch   0 |  2500/ 3817 batches | accuracy    0.613\n",
            "| epoch   0 |  3000/ 3817 batches | accuracy    0.622\n",
            "| epoch   0 |  3500/ 3817 batches | accuracy    0.615\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   0 | time: 12.29s | valid accuracy    0.628 \n",
            "-----------------------------------------------------------\n",
            "| epoch   1 |   500/ 3817 batches | accuracy    0.633\n",
            "| epoch   1 |  1000/ 3817 batches | accuracy    0.632\n",
            "| epoch   1 |  1500/ 3817 batches | accuracy    0.633\n",
            "| epoch   1 |  2000/ 3817 batches | accuracy    0.637\n",
            "| epoch   1 |  2500/ 3817 batches | accuracy    0.631\n",
            "| epoch   1 |  3000/ 3817 batches | accuracy    0.637\n",
            "| epoch   1 |  3500/ 3817 batches | accuracy    0.631\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time: 11.25s | valid accuracy    0.601 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 3817 batches | accuracy    0.664\n",
            "| epoch   2 |  1000/ 3817 batches | accuracy    0.663\n",
            "| epoch   2 |  1500/ 3817 batches | accuracy    0.667\n",
            "| epoch   2 |  2000/ 3817 batches | accuracy    0.670\n",
            "| epoch   2 |  2500/ 3817 batches | accuracy    0.669\n",
            "| epoch   2 |  3000/ 3817 batches | accuracy    0.668\n",
            "| epoch   2 |  3500/ 3817 batches | accuracy    0.670\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time: 10.50s | valid accuracy    0.648 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 3817 batches | accuracy    0.663\n",
            "| epoch   3 |  1000/ 3817 batches | accuracy    0.670\n",
            "| epoch   3 |  1500/ 3817 batches | accuracy    0.668\n",
            "| epoch   3 |  2000/ 3817 batches | accuracy    0.671\n",
            "| epoch   3 |  2500/ 3817 batches | accuracy    0.671\n",
            "| epoch   3 |  3000/ 3817 batches | accuracy    0.666\n",
            "| epoch   3 |  3500/ 3817 batches | accuracy    0.671\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time: 10.84s | valid accuracy    0.650 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 3817 batches | accuracy    0.668\n",
            "| epoch   4 |  1000/ 3817 batches | accuracy    0.674\n",
            "| epoch   4 |  1500/ 3817 batches | accuracy    0.672\n",
            "| epoch   4 |  2000/ 3817 batches | accuracy    0.669\n",
            "| epoch   4 |  2500/ 3817 batches | accuracy    0.672\n",
            "| epoch   4 |  3000/ 3817 batches | accuracy    0.673\n",
            "| epoch   4 |  3500/ 3817 batches | accuracy    0.671\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time: 10.66s | valid accuracy    0.648 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 3817 batches | accuracy    0.681\n",
            "| epoch   5 |  1000/ 3817 batches | accuracy    0.672\n",
            "| epoch   5 |  1500/ 3817 batches | accuracy    0.675\n",
            "| epoch   5 |  2000/ 3817 batches | accuracy    0.673\n",
            "| epoch   5 |  2500/ 3817 batches | accuracy    0.674\n",
            "| epoch   5 |  3000/ 3817 batches | accuracy    0.675\n",
            "| epoch   5 |  3500/ 3817 batches | accuracy    0.676\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time: 10.52s | valid accuracy    0.650 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 3817 batches | accuracy    0.673\n",
            "| epoch   6 |  1000/ 3817 batches | accuracy    0.673\n",
            "| epoch   6 |  1500/ 3817 batches | accuracy    0.678\n",
            "| epoch   6 |  2000/ 3817 batches | accuracy    0.673\n",
            "| epoch   6 |  2500/ 3817 batches | accuracy    0.676\n",
            "| epoch   6 |  3000/ 3817 batches | accuracy    0.675\n",
            "| epoch   6 |  3500/ 3817 batches | accuracy    0.672\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time: 10.13s | valid accuracy    0.649 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 3817 batches | accuracy    0.678\n",
            "| epoch   7 |  1000/ 3817 batches | accuracy    0.675\n",
            "| epoch   7 |  1500/ 3817 batches | accuracy    0.673\n",
            "| epoch   7 |  2000/ 3817 batches | accuracy    0.673\n",
            "| epoch   7 |  2500/ 3817 batches | accuracy    0.676\n",
            "| epoch   7 |  3000/ 3817 batches | accuracy    0.676\n",
            "| epoch   7 |  3500/ 3817 batches | accuracy    0.675\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time: 10.44s | valid accuracy    0.649 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 3817 batches | accuracy    0.675\n",
            "| epoch   8 |  1000/ 3817 batches | accuracy    0.676\n",
            "| epoch   8 |  1500/ 3817 batches | accuracy    0.673\n",
            "| epoch   8 |  2000/ 3817 batches | accuracy    0.675\n",
            "| epoch   8 |  2500/ 3817 batches | accuracy    0.676\n",
            "| epoch   8 |  3000/ 3817 batches | accuracy    0.673\n",
            "| epoch   8 |  3500/ 3817 batches | accuracy    0.675\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time: 10.39s | valid accuracy    0.649 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 3817 batches | accuracy    0.673\n",
            "| epoch   9 |  1000/ 3817 batches | accuracy    0.679\n",
            "| epoch   9 |  1500/ 3817 batches | accuracy    0.674\n",
            "| epoch   9 |  2000/ 3817 batches | accuracy    0.677\n",
            "| epoch   9 |  2500/ 3817 batches | accuracy    0.676\n",
            "| epoch   9 |  3000/ 3817 batches | accuracy    0.673\n",
            "| epoch   9 |  3500/ 3817 batches | accuracy    0.674\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time: 10.41s | valid accuracy    0.649 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def train(dataloader, model=model):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predicted_label = model(text, offsets)\n",
        "        loss = criterion(predicted_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
        "                \"| accuracy {:8.3f}\".format(\n",
        "                    epoch, idx, len(dataloader), total_acc / total_count\n",
        "                )\n",
        "            )\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(dataloader, model=model):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for _, (label, text, offsets) in enumerate(dataloader):\n",
        "            predicted_label = model(text, offsets)\n",
        "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc / total_count\n",
        "\n",
        "\n",
        "            \n",
        "# Hyperparameters\n",
        "EPOCHS = 10  # epoch\n",
        "LR = 5  # learning rate\n",
        "BATCH_SIZE = 64  # batch size for training\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "\n",
        "train_iter = df_train.iterrows()\n",
        "test_iter = df_test.iterrows()\n",
        "\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "split_train_, split_valid_ = random_split(\n",
        "    train_dataset, [num_train, len(train_dataset) - num_train]\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "\n",
        "for epoch in range(0, EPOCHS):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "        scheduler.step()\n",
        "    else:\n",
        "        total_accu = accu_val\n",
        "    print(\"-\" * 59)\n",
        "    print(\n",
        "        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
        "        \"valid accuracy {:8.3f} \".format(\n",
        "            epoch, time.time() - epoch_start_time, accu_val\n",
        "        )\n",
        "    )\n",
        "    print(\"-\" * 59)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking the results of test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXnAoQjHTSbu",
        "outputId": "96f4070a-7749-4cdd-d4e3-22a4c42e26fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking the results of test dataset.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test accuracy    65.27%\n"
          ]
        }
      ],
      "source": [
        "print(\"Checking the results of test dataset.\")\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print(\"test accuracy {:8.2f}\".format(accu_test*100)+\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKpXSlDvTSbu",
        "outputId": "1dc67a55-80fd-4488-b7d6-4b02e64b5055"
      },
      "outputs": [],
      "source": [
        "def predict_no_context(text, text_pipeline=text_pipeline):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(text_pipeline(text))\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() == 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Context Approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_pipeline = lambda x, y: (vocab(tokenizer(str(x))), vocab(tokenizer(str(y))))\n",
        "label_pipeline = lambda x: int(x)\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_parent_list, text_post_list = [], [], []\n",
        "    offsets_parent, offsets_post = [0], [0]\n",
        "    for index, row in batch:\n",
        "        label = row['label']\n",
        "        text_post = row['text_post']\n",
        "        text_parent = row['text_parent']\n",
        "        label_list.append(label_pipeline(label))\n",
        "        tokens_parent, tokens_post = text_pipeline(text_parent, text_post)\n",
        "        processed_text_parent = torch.tensor(tokens_parent, dtype=torch.int64)\n",
        "        processed_text_post = torch.tensor(tokens_post, dtype=torch.int64)\n",
        "        text_parent_list.append(processed_text_parent)\n",
        "        text_post_list.append(processed_text_post)\n",
        "        offsets_parent.append(processed_text_parent.size(0))\n",
        "        offsets_post.append(processed_text_post.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.float)\n",
        "    offsets_parent = torch.tensor(offsets_parent[:-1]).cumsum(dim=0)\n",
        "    offsets_post = torch.tensor(offsets_post[:-1]).cumsum(dim=0)\n",
        "    text_parent_list = torch.cat(text_parent_list)\n",
        "    text_post_list = torch.cat(text_post_list)\n",
        "    return (label_list.to(device), text_parent_list.to(device), text_post_list.to(device), \n",
        "            offsets_parent.to(device), offsets_post.to(device))\n",
        "\n",
        "train_iter = df_train.iterrows()\n",
        "dataloader = DataLoader(\n",
        "    train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TextClassificationModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, embed_dim_post, hidden_dim):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding_parent = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
        "        self.embedding_post = nn.EmbeddingBag(vocab_size, embed_dim_post, sparse=False)\n",
        "        self.hidden = nn.Linear(embed_dim*2, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding_parent.weight.data.uniform_(-initrange, initrange)\n",
        "        self.embedding_post.weight.data.uniform_(-initrange, initrange)\n",
        "        self.hidden.weight.data.uniform_(-initrange, initrange)\n",
        "        self.hidden.bias.data.zero_()\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text_parent, text_post, offsets_parent, offsets_post):\n",
        "        embedded_parent = self.embedding_parent(text_parent, offsets_parent)\n",
        "        embedded_post = self.embedding_parent(text_post, offsets_post)\n",
        "        embedded = torch.hstack([embedded_parent,embedded_post])\n",
        "        middle = self.hidden(torch.sigmoid(embedded))\n",
        "        output = self.fc(torch.sigmoid(middle))\n",
        "        return torch.sigmoid(output).squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_iter = df_test.iterrows()\n",
        "emsize = 64\n",
        "embed_dim_post = 96\n",
        "hidden_size = 64\n",
        "model2 = TextClassificationModel(vocab_size, emsize, embed_dim_post, hidden_size).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training!\n",
            "| epoch   0 |   500/ 3817 batches | accuracy    0.494\n",
            "| epoch   0 |  1000/ 3817 batches | accuracy    0.503\n",
            "| epoch   0 |  1500/ 3817 batches | accuracy    0.499\n",
            "| epoch   0 |  2000/ 3817 batches | accuracy    0.500\n",
            "| epoch   0 |  2500/ 3817 batches | accuracy    0.505\n",
            "| epoch   0 |  3000/ 3817 batches | accuracy    0.498\n",
            "| epoch   0 |  3500/ 3817 batches | accuracy    0.501\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   0 | time: 17.95s | valid accuracy    0.500 \n",
            "-----------------------------------------------------------\n",
            "| epoch   1 |   500/ 3817 batches | accuracy    0.506\n",
            "| epoch   1 |  1000/ 3817 batches | accuracy    0.513\n",
            "| epoch   1 |  1500/ 3817 batches | accuracy    0.518\n",
            "| epoch   1 |  2000/ 3817 batches | accuracy    0.517\n",
            "| epoch   1 |  2500/ 3817 batches | accuracy    0.521\n",
            "| epoch   1 |  3000/ 3817 batches | accuracy    0.530\n",
            "| epoch   1 |  3500/ 3817 batches | accuracy    0.540\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time: 17.56s | valid accuracy    0.499 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 3817 batches | accuracy    0.576\n",
            "| epoch   2 |  1000/ 3817 batches | accuracy    0.579\n",
            "| epoch   2 |  1500/ 3817 batches | accuracy    0.579\n",
            "| epoch   2 |  2000/ 3817 batches | accuracy    0.586\n",
            "| epoch   2 |  2500/ 3817 batches | accuracy    0.585\n",
            "| epoch   2 |  3000/ 3817 batches | accuracy    0.586\n",
            "| epoch   2 |  3500/ 3817 batches | accuracy    0.587\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time: 17.33s | valid accuracy    0.591 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 3817 batches | accuracy    0.590\n",
            "| epoch   3 |  1000/ 3817 batches | accuracy    0.591\n",
            "| epoch   3 |  1500/ 3817 batches | accuracy    0.593\n",
            "| epoch   3 |  2000/ 3817 batches | accuracy    0.593\n",
            "| epoch   3 |  2500/ 3817 batches | accuracy    0.590\n",
            "| epoch   3 |  3000/ 3817 batches | accuracy    0.595\n",
            "| epoch   3 |  3500/ 3817 batches | accuracy    0.590\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time: 17.74s | valid accuracy    0.576 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 3817 batches | accuracy    0.599\n",
            "| epoch   4 |  1000/ 3817 batches | accuracy    0.600\n",
            "| epoch   4 |  1500/ 3817 batches | accuracy    0.606\n",
            "| epoch   4 |  2000/ 3817 batches | accuracy    0.600\n",
            "| epoch   4 |  2500/ 3817 batches | accuracy    0.598\n",
            "| epoch   4 |  3000/ 3817 batches | accuracy    0.595\n",
            "| epoch   4 |  3500/ 3817 batches | accuracy    0.603\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time: 17.69s | valid accuracy    0.599 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 3817 batches | accuracy    0.599\n",
            "| epoch   5 |  1000/ 3817 batches | accuracy    0.601\n",
            "| epoch   5 |  1500/ 3817 batches | accuracy    0.602\n",
            "| epoch   5 |  2000/ 3817 batches | accuracy    0.598\n",
            "| epoch   5 |  2500/ 3817 batches | accuracy    0.606\n",
            "| epoch   5 |  3000/ 3817 batches | accuracy    0.598\n",
            "| epoch   5 |  3500/ 3817 batches | accuracy    0.605\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time: 18.62s | valid accuracy    0.600 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 3817 batches | accuracy    0.603\n",
            "| epoch   6 |  1000/ 3817 batches | accuracy    0.605\n",
            "| epoch   6 |  1500/ 3817 batches | accuracy    0.601\n",
            "| epoch   6 |  2000/ 3817 batches | accuracy    0.601\n",
            "| epoch   6 |  2500/ 3817 batches | accuracy    0.599\n",
            "| epoch   6 |  3000/ 3817 batches | accuracy    0.601\n",
            "| epoch   6 |  3500/ 3817 batches | accuracy    0.605\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time: 18.16s | valid accuracy    0.601 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 3817 batches | accuracy    0.598\n",
            "| epoch   7 |  1000/ 3817 batches | accuracy    0.604\n",
            "| epoch   7 |  1500/ 3817 batches | accuracy    0.600\n",
            "| epoch   7 |  2000/ 3817 batches | accuracy    0.606\n",
            "| epoch   7 |  2500/ 3817 batches | accuracy    0.604\n",
            "| epoch   7 |  3000/ 3817 batches | accuracy    0.603\n",
            "| epoch   7 |  3500/ 3817 batches | accuracy    0.605\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time: 18.57s | valid accuracy    0.602 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 3817 batches | accuracy    0.606\n",
            "| epoch   8 |  1000/ 3817 batches | accuracy    0.605\n",
            "| epoch   8 |  1500/ 3817 batches | accuracy    0.598\n",
            "| epoch   8 |  2000/ 3817 batches | accuracy    0.600\n",
            "| epoch   8 |  2500/ 3817 batches | accuracy    0.611\n",
            "| epoch   8 |  3000/ 3817 batches | accuracy    0.607\n",
            "| epoch   8 |  3500/ 3817 batches | accuracy    0.600\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time: 17.78s | valid accuracy    0.604 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 3817 batches | accuracy    0.605\n",
            "| epoch   9 |  1000/ 3817 batches | accuracy    0.604\n",
            "| epoch   9 |  1500/ 3817 batches | accuracy    0.607\n",
            "| epoch   9 |  2000/ 3817 batches | accuracy    0.603\n",
            "| epoch   9 |  2500/ 3817 batches | accuracy    0.609\n",
            "| epoch   9 |  3000/ 3817 batches | accuracy    0.610\n",
            "| epoch   9 |  3500/ 3817 batches | accuracy    0.602\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time: 17.95s | valid accuracy    0.604 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def train(dataloader, model=model2):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text_parent, text_post, offsets_parent, offsets_post) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predicted_label = model(text_parent, text_post, offsets_parent, offsets_post)\n",
        "        loss = criterion(predicted_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        predicted_label[predicted_label > 0.5] = 1\n",
        "        predicted_label[predicted_label <= 0.5] = 0\n",
        "        total_acc += (predicted_label == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
        "                \"| accuracy {:8.3f}\".format(\n",
        "                    epoch, idx, len(dataloader), total_acc / total_count\n",
        "                )\n",
        "            )\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "\n",
        "def evaluate(dataloader, model=model2):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text_parent, text_post, offsets_parent, offsets_post) in enumerate(dataloader):\n",
        "            predicted_label = model(text_parent, text_post, offsets_parent, offsets_post)\n",
        "            loss = criterion(predicted_label, label)\n",
        "            predicted_label[predicted_label > 0.5] = 1\n",
        "            predicted_label[predicted_label <= 0.5] = 0\n",
        "            total_acc += (predicted_label == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc / total_count\n",
        "\n",
        "# Hyperparameters\n",
        "EPOCHS = 10  # epoch\n",
        "LR = 5  # learning rate\n",
        "BATCH_SIZE = 64  # batch size for training\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model2.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "train_iter = df_train.iterrows()\n",
        "test_iter = df_test.iterrows()\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "split_train_, split_valid_ = random_split(\n",
        "    train_dataset, [num_train, len(train_dataset) - num_train]\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "\n",
        "print(\"Starting training!\")\n",
        "for epoch in range(0, EPOCHS):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "        scheduler.step()\n",
        "    else:\n",
        "        total_accu = accu_val\n",
        "    print(\"-\" * 59)\n",
        "    print(\n",
        "        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
        "        \"valid accuracy {:8.3f} \".format(\n",
        "            epoch, time.time() - epoch_start_time, accu_val\n",
        "        )\n",
        "    )\n",
        "    print(\"-\" * 59)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking the results of test dataset.\n",
            "test accuracy    60.69%\n"
          ]
        }
      ],
      "source": [
        "print(\"Checking the results of test dataset.\")\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print(\"test accuracy {:8.2f}\".format(accu_test*100)+\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_context(text_parent, text_post, text_pipeline=text_pipeline):\n",
        "    with torch.no_grad():\n",
        "        text_parent, text_post = text_pipeline(text_parent, text_post)\n",
        "        output = model2( torch.tensor(text_parent), torch.tensor(text_post), \n",
        "                        torch.tensor([0]), torch.tensor([0]) )\n",
        "        return output.item() > 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## VADER Sentiment Analysis Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With VADER approach we can take all the words in a sentence and then set a value, either negative, positive or neutral and combines those values in order to tell us if the sentence itself is more globally positive or negative. VADER gives us values from -1 to 1 for each word and a global compound (which we will be using here). From [6] we have a study showing that most of the time sarcasm comes with positive sentences, but in a negative situation or context. For simplicity, we will be using VADER as a voter in our final decision by defining a sentence as sarcastic when it has a positive or neutral compound in the answer, otherwise it will be non sarcastic; together with a negative or neutral context. It is important to highlight that VADER doesn't take into account the relationship between the words, which is very important in the real world. But it will be used here as voter for simplicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking the results of test dataset.\n",
            "test accuracy    50.38%\n"
          ]
        }
      ],
      "source": [
        "test_iter = df_test.iterrows()\n",
        "\n",
        "def evaluate():\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    for _, row in test_iter:\n",
        "        label = row['label']\n",
        "        text_post = str(row['text_post'])\n",
        "        text_parent = str(row['text_parent'])\n",
        "        predicted_label = predict_vader(text_parent, text_post)\n",
        "        total_acc += (predicted_label == (label==1))\n",
        "        total_count += 1\n",
        "    \n",
        "    return total_acc / total_count\n",
        "\n",
        "\n",
        "def predict_vader(context, answer):\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    vader1_result = sia.polarity_scores(context)[\"compound\"]\n",
        "    vader2_result = sia.polarity_scores(answer)[\"compound\"]\n",
        "    result = (vader1_result <= 0 and vader2_result >= 0)\n",
        "    return result\n",
        "\n",
        "\n",
        "print(\"Checking the results of test dataset.\")\n",
        "accu_test = evaluate()\n",
        "print(\"test accuracy {:8.2f}\".format(accu_test*100)+\"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demonstration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the end, to demonstrate our sarcasm recognition system, we have a voting system. Each approach developed will give a vote, 0 for non sarcastic, 1 for sarcastic, and if the sum of the votes is greater than 1 (2 or 3) it means that the input is sarcastic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "Situation  0 : When something bad happens\n",
            "Remark:  That's just what I needed today!\n",
            "M1:  False\n",
            "M2:  True\n",
            "M3:  True\n",
            "Voting Result:  True\n",
            "--------------------\n",
            "Situation  1 : When you expected something to happen, especially after warning someone about it\n",
            "Remark:  Well, what a surprise.\n",
            "M1:  True\n",
            "M2:  True\n",
            "M3:  True\n",
            "Voting Result:  True\n",
            "--------------------\n",
            "Situation  2 : Mine operator in accident had 57 safety violations last month alone and and did not install a required ventilation system that would have prevented the disasterWhen a roommate is acting bizarre\n",
            "Remark:  How does this compare to other mine operationsIs it time for your medication or mine?\n",
            "M1:  False\n",
            "M2:  False\n",
            "M3:  True\n",
            "Voting Result:  False\n",
            "--------------------\n",
            "Situation  3 : When someone says something that is very obvious\n",
            "Remark:  Really, Sherlock? No! You are clever.\n",
            "M1:  True\n",
            "M2:  True\n",
            "M3:  True\n",
            "Voting Result:  True\n"
          ]
        }
      ],
      "source": [
        "# https://www.yourdictionary.com/articles/examples-sarcasm-meaning-types\n",
        "input1 = [\n",
        "    \"When something bad happens\",\n",
        "    \"When you expected something to happen, especially after warning someone about it\",\n",
        "    \"Mine operator in accident had 57 safety violations last month alone and and did not install a required ventilation system that would have prevented the disaster\"\n",
        "    \"When a roommate is acting bizarre\",\n",
        "    \"When someone says something that is very obvious\"\n",
        "          ]\n",
        "\n",
        "\n",
        "input2 = [\n",
        "    \"That's just what I needed today!\",\n",
        "    \"Well, what a surprise.\",\n",
        "    \"How does this compare to other mine operations\"\n",
        "    \"Is it time for your medication or mine?\",\n",
        "    \"Really, Sherlock? No! You are clever.\"\n",
        "          ]\n",
        "\n",
        "model = model.to(\"cpu\")\n",
        "model2 = model2.to(\"cpu\")\n",
        "\n",
        "for i in range(0, len(input1)):\n",
        "    noContext_vote = predict_no_context(input2[i])\n",
        "    context_vote = predict_context(input1[i], input2[i])\n",
        "    vader_vote = predict_vader(input1[i], input2[i])\n",
        "    result = sum([noContext_vote, context_vote, vader_vote]) > 1\n",
        "\n",
        "    print(\"--------------------\\nSituation \", i, \":\", input1[i])\n",
        "    print(\"Remark: \", input2[i])\n",
        "    print(\"M1: \", noContext_vote)\n",
        "    print(\"M2: \", context_vote)\n",
        "    print(\"M3: \", vader_vote)\n",
        "    print(\"Voting Result: \", result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9Xlii7NXuOR"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    Throughout our work, we developed 3 approaches for sarcasm recognition so we were able to apply the Condorcet's jury theorem, so we obtained a more trustful and robust system to give us binary predictions in either a setence is sarcastic or not. We have worked with the SARC corpus, containing Reddit comments self annotated by the authors.\n",
        "\n",
        "    For the first model, we designed a simple sarcasm recoginition system, taking only a setence as input for the analysis (no context), based on a Pytorch example for sentiment analysis. There we had a test accuracy over 65%.\n",
        "\n",
        "    Concerning the second model, using the same self-annotated dataset, we made some modifications in the first model in order to take into account the context in which the comment was written (parent text). This time we achieved a test accuracy over 50%.\n",
        "\n",
        "    Finally, as a way to have a third opinion in the voting process suggested by the Condorcet's jury theorem and explored in [7], we used the pretrained model VADER to do sentiment analysis with context. The ideia here was to consider the contrast between the situation and the target sentence, in [6] it was studied the relationship between negative situations/contexts and positive answers/sentences as a way to express sarcasm in the social media Twitter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap0SJ_Ja4QQd"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUsZLcPc4SAd"
      },
      "source": [
        "[1] Khodak, M., Saunshi, N. and Vodrahalli, K., 2017. A large self-annotated corpus for sarcasm. arXiv preprint arXiv:1704.05579.\n",
        "\n",
        "[2] Attardo, S. and Raskin, V., 1991. Script theory revis (it) ed: Joke similarity and joke representation model.\n",
        "\n",
        "[3] Farha, I.A., Oprea, S., Wilson, S. and Magdy, W., 2022, July. Semeval-2022 task 6: isarcasmeval, intended sarcasm detection in english and arabic. In The 16th International Workshop on Semantic Evaluation 2022 (pp. 802-814). Association for Computational Linguistics.\n",
        "\n",
        "[4] Ashwitha, A., Shruthi, G., Shruthi, H.R., Upadhyaya, M., Ray, A.P. and Manjunath, T.C., 2021. Sarcasm detection in natural language processing. Materials Today: Proceedings, 37, pp.3324-3331.\n",
        "\n",
        "[5] Adam Paszke et al. “Automatic differentiation in PyTorch”. In: (2017).\n",
        "\n",
        "[6] Riloff, E., Qadir, A., Surve, P., De Silva, L., Gilbert, N. and Huang, R., 2013, October. Sarcasm as contrast between a positive sentiment and negative situation. In Proceedings of the 2013 conference on empirical methods in natural language processing (pp. 704-714).\n",
        "\n",
        "[7] Ariharan, V., Eswaran, S.P., Vempati, S. and Anjum, N., 2019. Machine learning quorum decider (MLQD) for large scale IoT deployments. Procedia Computer Science, 151, pp.959-964."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
